dag:
  dag_id: 'init_castor_dag'
  default_args: '{"owner": "castor", "start_date": "2021-06-13"}'
  schedule_interval: '@once'
  catchup: False
  tags:
    - example
tasks:
    - name: 'start'
      strategy: 'DummyOperatorStrategy'
    - name: 't1'
      strategy: 'PythonOperatorStrategy'
      depends_on:
        - 'start'
      args:
        retries: 2
        trigger_rule: 'all_success'
        provide_context: True
        python_callable: 'print_params'
        op_kwargs:
          param1: 'value1'
    - name: 't2'
      strategy: 'PythonOperatorStrategy'
      depends_on:
        - 'start'
      args:
        retries: 2
        trigger_rule: 'all_success'
        provide_context: True
        python_callable: 'print_params'
        op_kwargs:
          param1: 'value1'
    - name: 't3'
      strategy: 'PythonOperatorStrategy'
      depends_on:
        - 't1'
        - 't2'
      args:
        retries: 2
        trigger_rule: 'all_success'
        provide_context: True
        python_callable: 'print_params'
        op_kwargs:
          param1: 'value1'
    - name: 't4'
      strategy: 'NotebookOperatorStrategy'
      depends_on:
        - 't3'
      args:
        retries: 2
        trigger_rule: 'all_success'
        provide_context: True
        runner: 'DATABRICKS'
        databricks_conn_id: '<CONNECTION_ID (Optional)>'
        notebook_path: '<NOTEBOOK_PATH_IN_DATABRICKS_WORKSPACE>'
        cluster_id: '<CLUSTER_ID (optional)>'
        new_cluster:
          spark_version: '2.1.0-db3-scala2.11'
          node_type_id: 'r3.xlarge'
          aws_attributes:
            availability: 'ON_DEMAND'
          num_workers: 8
    - name: 'end'
      strategy: 'DummyOperatorStrategy'
      depends_on:
        - 't4'